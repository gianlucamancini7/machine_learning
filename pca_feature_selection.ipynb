{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#allows to print the dataframe nicely\n",
    "from IPython.core import display as ICD\n",
    "!pip install plotly\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "import plotly.tools as tls\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import additional packages to insepct data and clean them\n",
    "import pandas as pd\n",
    "import os \n",
    "import random \n",
    "from zipfile import ZipFile\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import helping functions from the implementation file\n",
    "#from proj1_helpers import load_csv_data\n",
    "from proj1_helpers import *\n",
    "import implementations\n",
    "from additional_implementations import *\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipped files from the github repository\n",
    "data_folder='./data/'\n",
    "zip_file = ZipFile(data_folder+'all.zip')\n",
    "# zip file creates a list of files with certain properties\n",
    "zip_file.infolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we want to access the 'filename' property in the zipfile variable\n",
    "# and we create a dictionary of dataframe\n",
    "dfs = {text_file.filename: pd.read_csv(zip_file.open(text_file.filename))\n",
    "       for text_file in zip_file.infolist()\n",
    "       if text_file.filename.endswith('.csv')}\n",
    "df_train=dfs['train.csv']\n",
    "df_test=dfs['test.csv']\n",
    "df_sample_submission=dfs['sample-submission.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pca=df_train.drop(columns=['Prediction', 'Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts={}\n",
    "for column_name in df_train_pca.columns.values:\n",
    "    \n",
    "    check=df_train_pca[column_name]==-999.0\n",
    "    counts[column_name]=np.sum(check.astype('int'))\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pca=df_train_pca.drop(columns=['PRI_jet_subleading_pt', 'PRI_jet_subleading_eta', 'PRI_jet_subleading_phi', 'DER_lep_eta_centrality', 'DER_prodeta_jet_jet', 'DER_mass_jet_jet', 'DER_deltaeta_jet_jet','PRI_jet_leading_pt','PRI_jet_leading_eta','PRI_jet_leading_phi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median=np.median(df_train_pca['DER_mass_MMC'])\n",
    "df_train_pca['DER_mass_MMC'][df_train_pca['DER_mass_MMC']==-999.0]=median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_train_pca.iloc[:,1:].columns.values\n",
    "df_train_pca_std=pd.DataFrame()\n",
    "\n",
    "for feature in features:\n",
    "    \n",
    "    df_train_pca_std[feature]=standardize_personal(df_train_pca[feature])\n",
    "df_train_pca_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_df_train_pca_std=np.cov(df_train_pca_std.T)\n",
    "eig_vals, eig_vecs = np.linalg.eig(cov_df_train_pca_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of (eigenvalue, eigenvector) tuples\n",
    "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "\n",
    "# Sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "eig_pairs.sort()\n",
    "eig_pairs.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = sum(eig_vals)\n",
    "var_exp = [(i / tot)*100 for i in sorted(eig_vals, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "\n",
    "trace1 = Bar(\n",
    "        x=['PC %s' %i for i in range(1,20)],\n",
    "        y=var_exp,\n",
    "        showlegend=False)\n",
    "\n",
    "trace2 = Scatter(\n",
    "        x=['PC %s' %i for i in range(1,20)], \n",
    "        y=cum_var_exp,\n",
    "        name='cumulative explained variance')\n",
    "\n",
    "data = Data([trace1, trace2])\n",
    "\n",
    "layout=Layout(\n",
    "        yaxis=YAxis(title='Explained variance in percent'),\n",
    "        title='Explained variance by different principal components')\n",
    "\n",
    "fig = Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_pairs[0][1].reshape(20,1)\n",
    "number_features=20\n",
    "#decide how many principal components i get\n",
    "number_pa=15\n",
    "#define matrix to be filled in\n",
    "matrix_w=np.ones((number_features, number_pa))\n",
    "for i in range(number_pa):\n",
    "    matrix_w[:,i] = eig_pairs[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_train_independent_std_transf = df_features_train_independent_std.dot(matrix_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pca=np.array(df_train['Prediction'])\n",
    "y_train_pca[np.where(y_train_pca=='b')] = -1.\n",
    "y_train_pca[np.where(y_train_pca=='s')] = 1.\n",
    "y_train_pca=y_train_pca.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_train_pca_polynomial=polynomial_features_simple(df_train_pca, 9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
